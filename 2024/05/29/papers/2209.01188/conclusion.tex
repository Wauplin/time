\section{Conclusion}

This paper introduces \textsc{Petals}, a system for efficient collaborative inference and fine-tuning of large language models. We offer a user-friendly generation interface and a flexible API to access models served over the Internet. We use 8-bit compression that reduces the resource requirements to run very large models. In addition, we develop algorithms for reliable routing and load balancing.

% Since \textsc{Petals} is open-source, we would like it to evolve based on the community's feedback, incorporating relevant research advances and adding support for features in demand.
With the release of this system, we hope to broaden access to LLMs and pave the road to applications, studies or research questions that were previously not possible or simply too expensive.

% [Commented since the Discussion section has been moved to the main text]
% Running LLMs over the Internet raises a broad range of related questions. One of them is privacy: how to avoid revealing private data to outside peers. Another challenge is to ensure that participants can benefit from this system equitably, i.e. in proportion to their contribution.
% We discuss future problems such as privacy, security, and incentive structures in Appendix~\ref{sect:discussion}.
